{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1198ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               False\n",
       "SepalLengthCm    False\n",
       "SepalWidthCm     False\n",
       "PetalLengthCm    False\n",
       "PetalWidthCm     False\n",
       "Species          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply Linear Discriminant Analysis (LDA) on Iris.csv dataset to reduce dimensionality of data tok=2.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing ,metrics\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "sns.set(style=\"white\",color_codes=True)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataSet_Iris = pd.read_csv('Iris.csv')\n",
    "dataSet_Iris.head()\n",
    "\n",
    "dataSet_Iris.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c1dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "x=dataSet_Iris.iloc[:,1:-1]\n",
    "y=dataSet_Iris.iloc[:,-1]\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab42d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train , X_test, y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "le= LabelEncoder()\n",
    "y= le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d2ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 2) (45, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=2)\n",
    "X_train = lda.fit_transform(X_train,y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce28f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3271389814.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    Both LDA and PCA rely on linear transformations and aim to maximize the variance in a lower dimension .\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Briefly identify the difference between PCA and LDA\n",
    "\n",
    "Both LDA and PCA rely on linear transformations and aim to maximize the variance in a lower dimension . \n",
    "PCA is an unsupervised learning algorithm while LDA is a supervised learning algorithm .\n",
    "This means that PCA finds directions of maximum variance regardless of class labels\n",
    "while LDA finds directions of maximum class seperability\n",
    "\n",
    "It reduces the features into a smaller subset of orthogonal variables , \n",
    "called principal components -linear combinations of the original variables.\n",
    "The first component captures the largest variability of the data ,while the second captures the second largestand so on\n",
    "\n",
    "LDA finds the linear discriminants in order to maximize the variance between the different categories \n",
    "while minimizing the variance within the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628c2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
